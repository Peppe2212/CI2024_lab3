{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: 8-Puzzle Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8-puzzle problem is a classic sliding puzzle consisting of a 3x3 grid with eight numbered tiles and one empty space. The objective is to move the tiles around by sliding them into the empty space to reach a specific goal configuration, typically in ascending order from 1 to 8 with the empty space in the bottom-right corner:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|1|2|3|\n",
    "|---|---|---|\n",
    "|4|5|6|\n",
    "|7|8|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially the puzzle is in a randomized configuration (initial state), the challenge is to find the shortest path (or the minium number of actions) to order it in the configuration above (With zero in the bottom-right position). In this case, the solution requires 26 moves. The problem is typically solved using search algorithms such as A*, which relies on a heuristic function to guide the search towards the goal.\n",
    "\n",
    "For the heuristic, we will use Manhattan Distance, which sums the horizontal and vertical distances of each tile from its goal position. This heuristic is effective because it gives an estimate of the number of moves needed for each tile to reach its goal, considering that tiles can only move horizontally or vertically, not diagonally. This approach is commonly known as the city-block distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "from random import choice\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "\n",
    "PUZZLE_DIM = 3\n",
    "#PUZZLE_DIM = 4\n",
    "#PUZZLE_DIM = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some useful function that will be used in the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the tuple that represents an action\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])\n",
    "\n",
    "# Defining the function that return the available actions\n",
    "def available_actions(state: np.ndarray) -> list['action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "# Defining the function that permit to do an action on the actual state\n",
    "def do_action(state: np.ndarray, action: 'action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "# Defining the Manhattan distance\n",
    "def manhattan_distance(state):\n",
    "    dist = 0\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x][y]\n",
    "            if value != 0:\n",
    "                target_x, target_y = divmod(value - 1, PUZZLE_DIM)\n",
    "                dist += abs(target_x - x) + abs(target_y - y)\n",
    "    return dist\n",
    "\n",
    "# Function to print puzzle better\n",
    "def print_puzzle(state: np.ndarray):\n",
    "    for row in state:\n",
    "        print(' '.join(f'{num:2}' for num in row))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some costants, such as the puzzle dimension and the goal state we want to obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Showing the final state we want to obtain\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1  2  3\n",
      " 4  5  6\n",
      " 7  8  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PUZZLE_DIM = 3\n",
    "\n",
    "GOAL_STATE = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "GOAL_TUPLE = tuple(map(tuple, GOAL_STATE))  \n",
    "\n",
    "logging.info(\" Showing the final state we want to obtain\\n\")\n",
    "print_puzzle(GOAL_STATE)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the initial random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Showing the starting state\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  7  6\n",
      " 2  8  3\n",
      " 4  1  5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating the state\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for _ in range(RANDOMIZE_STEPS):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "logging.info(\" Showing the starting state\\n\")\n",
    "\n",
    "print_puzzle(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A* algorithm (3x3 Puzzle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the A* function\n",
    "\n",
    "def a_star(initial_state):\n",
    "    open_set = []\n",
    "    visited = set()\n",
    "    \n",
    "    # Converte lo stato iniziale in una tupla immutabile per essere usata in un insieme\n",
    "    initial_tuple = tuple(map(tuple, initial_state))\n",
    "    heapq.heappush(open_set, (0, initial_tuple, 0, [], manhattan_distance(initial_state)))\n",
    "    \n",
    "    while open_set:\n",
    "        #Pop the node with the minimum cost \n",
    "        _, current_tuple, g, path, _ = heapq.heappop(open_set)\n",
    "        # g: number of action\n",
    "        # path: list of action\n",
    "        \n",
    "        #Verify if we reached the GOAL_STATE\n",
    "        if current_tuple == GOAL_TUPLE:\n",
    "            print(\"Puzzle Solved!\")\n",
    "            print(\"Final state of the puzzle:\")\n",
    "            final_state = np.array(current_tuple)\n",
    "            print_puzzle(final_state) \n",
    "            # returning the number of actions and the list of did actions to solve the puzzle\n",
    "            return g, path\n",
    "        \n",
    "        #Marking the node as visited\n",
    "        visited.add(current_tuple)\n",
    "        \n",
    "        # Converting the current tuple into an np array to be able to compare it\n",
    "        current_state = np.array(current_tuple)\n",
    "        \n",
    "        for action in available_actions(current_state):\n",
    "            new_state = do_action(current_state, action)\n",
    "            new_state_tuple = tuple(map(tuple, new_state))\n",
    "\n",
    "            if new_state_tuple not in visited:\n",
    "                new_g = g+1\n",
    "                new_h = manhattan_distance(new_state)\n",
    "                new_f = new_g + new_h\n",
    "                heapq.heappush(open_set, (new_f, new_state_tuple, new_g, path + [action], new_h))\n",
    "            \n",
    "    return -1, []                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      " 0  7  6\n",
      " 2  8  3\n",
      " 4  1  5\n",
      "\n",
      "Puzzle Solved!\n",
      "Final state of the puzzle:\n",
      " 1  2  3\n",
      " 4  5  6\n",
      " 7  8  0\n",
      "\n",
      "Number of action used: 26\n",
      "Sequence (path) of the actions used:\n",
      "Action(pos1=(0, 0), pos2=(1, 0))\n",
      "Action(pos1=(1, 0), pos2=(1, 1))\n",
      "Action(pos1=(1, 1), pos2=(2, 1))\n",
      "Action(pos1=(2, 1), pos2=(2, 0))\n",
      "Action(pos1=(2, 0), pos2=(1, 0))\n",
      "Action(pos1=(1, 0), pos2=(1, 1))\n",
      "Action(pos1=(1, 1), pos2=(0, 1))\n",
      "Action(pos1=(0, 1), pos2=(0, 2))\n",
      "Action(pos1=(0, 2), pos2=(1, 2))\n",
      "Action(pos1=(1, 2), pos2=(1, 1))\n",
      "Action(pos1=(1, 1), pos2=(0, 1))\n",
      "Action(pos1=(0, 1), pos2=(0, 0))\n",
      "Action(pos1=(0, 0), pos2=(1, 0))\n",
      "Action(pos1=(1, 0), pos2=(2, 0))\n",
      "Action(pos1=(2, 0), pos2=(2, 1))\n",
      "Action(pos1=(2, 1), pos2=(1, 1))\n",
      "Action(pos1=(1, 1), pos2=(1, 2))\n",
      "Action(pos1=(1, 2), pos2=(2, 2))\n",
      "Action(pos1=(2, 2), pos2=(2, 1))\n",
      "Action(pos1=(2, 1), pos2=(1, 1))\n",
      "Action(pos1=(1, 1), pos2=(1, 0))\n",
      "Action(pos1=(1, 0), pos2=(2, 0))\n",
      "Action(pos1=(2, 0), pos2=(2, 1))\n",
      "Action(pos1=(2, 1), pos2=(1, 1))\n",
      "Action(pos1=(1, 1), pos2=(1, 2))\n",
      "Action(pos1=(1, 2), pos2=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "#Running the A*\n",
    "\n",
    "print(\"Initial state:\")\n",
    "print_puzzle(state)  \n",
    "\n",
    "num_action, sequence_ofAction = a_star(state)\n",
    "print(f\"Number of action used: {num_action}\")\n",
    "print(\"Sequence (path) of the actions used:\")\n",
    "for move in sequence_ofAction:\n",
    "    print(move)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
